{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Language-Model-Tutorial\" data-toc-modified-id=\"Language-Model-Tutorial-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Language Model Tutorial</a></span><ul class=\"toc-item\"><li><span><a href=\"#Getting-Started\" data-toc-modified-id=\"Getting-Started-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Getting Started</a></span></li><li><span><a href=\"#Our-Data\" data-toc-modified-id=\"Our-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Our Data</a></span></li><li><span><a href=\"#Counting\" data-toc-modified-id=\"Counting-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Counting</a></span><ul class=\"toc-item\"><li><span><a href=\"#Counting-Unigrams\" data-toc-modified-id=\"Counting-Unigrams-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Counting Unigrams</a></span></li><li><span><a href=\"#Counting-N-grams\" data-toc-modified-id=\"Counting-N-grams-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Counting N-grams</a></span></li><li><span><a href=\"#Predicting-N-grams\" data-toc-modified-id=\"Predicting-N-grams-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Predicting N-grams</a></span></li><li><span><a href=\"#Generating-N-grams!-Making-the-Language-Model-speak\" data-toc-modified-id=\"Generating-N-grams!-Making-the-Language-Model-speak-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Generating N-grams! Making the Language Model speak</a></span></li></ul></li><li><span><a href=\"#N-gram-Language-Models\" data-toc-modified-id=\"N-gram-Language-Models-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>N-gram Language Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Smoothing\" data-toc-modified-id=\"Smoothing-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Smoothing</a></span></li></ul></li></ul></li><li><span><a href=\"#Challenge-Exercises\" data-toc-modified-id=\"Challenge-Exercises-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Challenge Exercises</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Tutorial\n",
    "\n",
    "**Instructions**: \n",
    "In this tutorial, we will be creating an **n-gram language model** from scratch and using the language model in a variety of applications. \n",
    "\n",
    "Throughout this notebook, there will be a few **bolded** questions. These are questions for you to think about, and perhaps write some code to answer as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's import a set of libraries we will find useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aditi_khullar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "# for manipulating data\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# useful nlp methods\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "nltk.download('punkt')\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#printing\n",
    "from tabulate import tabulate\n",
    "\n",
    "# downloading data\n",
    "from urllib import request\n",
    "\n",
    "# a function to flatten a list\n",
    "flatten_list = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Data\n",
    "To start, we'll be working with the [Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus), a collection of English-language texts from 500 different sources grouped in 15 different categories.(e.g. fiction, news, ... etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.sls.hawaii.edu/bley-vroman/brown_nolines.txt'\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Fulton County Grand Jury said Friday an investigation of Atlanta\\'s recent primary election produced \"no evidence\" that any irregularities took place.   \\r\\nThe jury further said in term-end presentments that the City Executive Committee, which had over-all charge of the election, \"deserves the praise and thanks of the City of Atlanta\" for the manner in which the election was conducted.\\r\\n\\r\\nThe Se'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[0:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a set of newline-separated (\"\\r\\n\") sentences. In addition, on manual observation, we notice some lines are not broken into sentences perfectly. We will also split on \". \" as a crude way of catching these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Example line with multiple sentences--\n",
      "There has been more activity across the state line in Massachusetts than in Rhode Island in recent weeks toward enforcement of the Sunday sales laws. The statutes, similar in both the Bay State and Rhode Island and dating back in some instances to colonial times, severely limit the types of merchandise that may be sold on the Sabbath.   \n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced \"no evidence\" that any irregularities took place.\n",
      ">> sentence 1:   \n",
      ">> sentence 2: The jury further said in term-end presentments that the City Executive Committee, which had over-all charge of the election, \"deserves the praise and thanks of the City of Atlanta\" for the manner in which the election was conducted.\n",
      ">> sentence 3: \n",
      ">> sentence 4: The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible \"irregularities\" in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr&.\n"
     ]
    }
   ],
   "source": [
    "raw_sentences = raw.split('\\r\\n') # split by newline\n",
    "print('--Example line with multiple sentences--')\n",
    "print(raw_sentences[400]) # example line with a period in it\n",
    "\n",
    "raw_sentences = [re.split(r'(?<=\\.) ', sentence) for sentence in raw_sentences] # split by \". \"\n",
    "raw_sentences = flatten_list(raw_sentences)\n",
    "\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "     print('>> sentence {}:'.format(i), raw_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we note two things:\n",
    "\n",
    "1. Some sentences are blank (e.g. sentences 1 and 3). We'll want to remove those.\n",
    "2. Some words are capitalized while others are not. Some are proper nouns while others are the beginning of sentences. To help standardize this, let's lowercase all of the words (e.g. \"Only\" at the beginning of a sentence and \"only\" in the middle of a sentence are still the same).\n",
    "\n",
    "In order to build a language model. We also need to be able to split a sentence into words. Thankfully, there's a function from nltk called word_tokenize that can do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 50238 sentences in total.\n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: ['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "\n",
      ">> sentence 1: ['the', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']\n",
      "\n",
      ">> sentence 2: ['the', 'september-october', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'mayor-nominate', 'ivan', 'allen', 'jr', '&', '.']\n",
      "\n",
      ">> sentence 3: ['``', 'only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.']\n",
      "\n",
      ">> sentence 4: ['the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgia', \"'s\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(s):\n",
    "    # remove trailing whitespace\n",
    "    s = s.strip()\n",
    "    \n",
    "    # lowercase all tokens\n",
    "    s = s.lower()\n",
    "    \n",
    "    # split into tokens - TODO: this requires installing \"punkt\". Perhaps we should make a version that doesn't require installing anything\n",
    "    s = word_tokenize(s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "# preprocess each sentence and also remove empty sentences\n",
    "tokenized_sentences = [preprocess_sentence(s) for s in raw_sentences]\n",
    "tokenized_sentences = [s for s in tokenized_sentences if len(s) > 0]\n",
    "\n",
    "# print sample sentences\n",
    "print('We have {} sentences in total.'.format(len(tokenized_sentences)))\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "    print('>> sentence {}:'.format(i), tokenized_sentences[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is starting to look good. Again we'll point out a few things:\n",
    "\n",
    "1. Punctuation are their own tokens. Sometimes we will also choose to remove punctuation completely from our sentences. In . this example, we'll keep it for simplicity. \n",
    "2. As we'll see in the section below, tokenizing our sentences in this way makes it really easy to count n-grams moving forward.\n",
    "\n",
    "Note that you can also work with the **brown corpus available in the nltk library**. Above we started by using the raw corpus. NLTK pprovides you a handle on the words and sentences direcly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "#words\n",
    "nltk_words = brown.words()\n",
    "#sentences\n",
    "nltk_sents = brown.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Below we provide two other corpus options that you can work with for creating a language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corpus Option 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the various categories covered in Brown corpus. It will be interesting to note how the language model you create changes when you limit the underlying dataset to only couple of these categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sents = brown.sents(categories=['news', 'editorial', 'reviews'])\n",
    "#words\n",
    "nltk_words = brown.words(categories=['news', 'editorial', 'reviews'])\n",
    "#sentences\n",
    "nltk_sents = brown.sents(categories=['news', 'editorial', 'reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corpus Option 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a languge model on Macbeth's script. Do you think a Language model trained on Macbeth will be any different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "#words\n",
    "macbeth_words = gutenberg.words('shakespeare-macbeth.txt')\n",
    "#sentences\n",
    "macbeth_sents = gutenberg.sents('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into counting n=grams, let's do something a little simpler. What are the most common words (or \"unigrams\") in our corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram      count\n",
      "---------  -------\n",
      "the          69924\n",
      ",            58328\n",
      ".            48646\n",
      "of           36406\n",
      "and          28834\n",
      "to           26095\n",
      "a            23370\n",
      "in           21335\n",
      "that         10773\n",
      "is           10191\n"
     ]
    }
   ],
   "source": [
    "word_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "        word_counter[word] += 1\n",
    "print(tabulate([[item[0],item[1]] for item in word_counter.most_common(n=10)], headers = ['Unigram', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one might expect, we see words like \"the\", \"of\", \"and\"... etc. We can also plot this to see the relative frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c1d22b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gather the data\n",
    "most_common_words = word_counter.most_common(n=50)\n",
    "indexes = np.arange(len(most_common_words))\n",
    "labels = [l for l,v in most_common_words]\n",
    "values = [v for l,v in most_common_words]\n",
    "\n",
    "# create the plot\n",
    "width = 1\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes, labels, rotation=30)\n",
    "plt.title('Most common words in the Brown Corpus')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows a phenomenon commonly known as [Zipf's law](https://nlp.stanford.edu/IR-book/html/htmledition/zipfs-law-modeling-the-distribution-of-terms-1.html), which basically says that the most common words show up exponentially more often than less common words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "How does this change when you remove the stop words : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram      count\n",
      "---------  -------\n",
      ",            58328\n",
      ".            48646\n",
      "``            8837\n",
      "''            8805\n",
      "'s            5856\n",
      "&             5781\n",
      "one           3354\n",
      "<             3096\n",
      ">             3095\n",
      "would         2842\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "        if word not in stop_words:\n",
    "            word_counter[word] += 1\n",
    "print(tabulate([[item[0],item[1]] for item in word_counter.most_common(n=10)], headers = ['Unigram', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this change when you remove the stop words and the punctuations : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram      count\n",
      "---------  -------\n",
      "one           3354\n",
      "would         2842\n",
      "said          1957\n",
      "could         1774\n",
      "new           1630\n",
      "time          1589\n",
      "two           1409\n",
      "may           1398\n",
      "first         1359\n",
      "man           1325\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "        if word not in stop_words and word.isalpha():\n",
    "            word_counter[word] += 1\n",
    "print(tabulate([[item[0],item[1]] for item in word_counter.most_common(n=10)], headers = ['Unigram', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk conveniently provides functions to help us find the n-grams in a sentence. In the output of the cell below, you'll also notice that the beginning and ending n-grams are padded with ``<s>`` and ``</s>``. We can see these tokens as a special \"word\" that marks the beginning and end of sentences. This helps us use an n-gram even when computing probabilities for the first word of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--10 Bigram Samples--\n",
      "\n",
      "WORD1           WORD2\n",
      "--------------  --------------\n",
      "<s>             the\n",
      "the             fulton\n",
      "fulton          county\n",
      "county          grand\n",
      "grand           jury\n",
      "any             irregularities\n",
      "irregularities  took\n",
      "took            place\n",
      "place           .\n",
      ".               <\\s>\n",
      "\n",
      "--10 Trigram Samples--\n",
      "\n",
      "WORD1           WORD2           WORD3\n",
      "--------------  --------------  -------\n",
      "<s>             <s>             the\n",
      "<s>             the             fulton\n",
      "the             fulton          county\n",
      "fulton          county          grand\n",
      "county          grand           jury\n",
      "any             irregularities  took\n",
      "irregularities  took            place\n",
      "took            place           .\n",
      "place           .               <\\s>\n",
      ".               <\\s>            <\\s>\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_BEGIN = '<s>'\n",
    "SENTENCE_END = '<\\s>'\n",
    "sentence_0_bigrams = ngrams(tokenized_sentences[0], 2, pad_right=True, pad_left=True, \n",
    "                            left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END)\n",
    "sentence_0_trigrams = ngrams(tokenized_sentences[0], 3, pad_right=True, pad_left=True, \n",
    "                             left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END)\n",
    "sentence_0_bigrams = list(sentence_0_bigrams)\n",
    "sentence_0_trigrams = list(sentence_0_trigrams)\n",
    "\n",
    "# extra code to print the n-grams more nicely\n",
    "print('--10 Bigram Samples--\\n')\n",
    "print(tabulate([[w1, w2] for w1, w2 in sentence_0_bigrams[:5]+sentence_0_bigrams[-5:]], headers=['WORD1', 'WORD2']))\n",
    "print()\n",
    "print('--10 Trigram Samples--\\n')\n",
    "print(tabulate([[w1, w2, w3] for w1, w2, w3 in sentence_0_trigrams[:5]+sentence_0_trigrams[-5:]], headers=['WORD1', 'WORD2', 'WORD3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we can count trigrams and bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the most common bigrams? Do any of them surprise you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram            Count\n",
      "--------------  -------\n",
      "('.', '<\\\\s>')    48453\n",
      "('of', 'the')      9702\n",
      "(',', 'and')       6272\n",
      "('<s>', 'the')     6035\n",
      "('in', 'the')      5996\n",
      "(',', 'the')       3749\n",
      "('<s>', '``')      3655\n",
      "('to', 'the')      3439\n",
      "(\"''\", '.')        3375\n",
      "('<s>', 'he')      2725\n"
     ]
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "bigram_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for w1, w2 in ngrams(sentence, 2, pad_right=True, pad_left=True, \n",
    "                         left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END):\n",
    "        bigram_counter[(w1, w2)] += 1\n",
    "print(tabulate(bigram_counter.most_common(n=10), headers = [\"Bigram\", \"Count\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How about the most common trigrams?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram                    Count\n",
      "-----------------------  -------\n",
      "('.', '<\\\\s>', '<\\\\s>')    48453\n",
      "('<s>', '<s>', 'the')       6035\n",
      "('<s>', '<s>', '``')        3655\n",
      "(\"''\", '.', '<\\\\s>')        3360\n",
      "('<s>', '<s>', 'he')        2725\n",
      "('<s>', '<s>', 'it')        1913\n",
      "('<s>', '<s>', 'in')        1617\n",
      "('<s>', '<s>', 'i')         1328\n",
      "('#', '<\\\\s>', '<\\\\s>')     1265\n",
      "('<s>', '<s>', '#')         1254\n"
     ]
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "trigram_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for w1, w2, w3 in ngrams(sentence, 3, pad_right=True, pad_left=True, \n",
    "                             left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END):\n",
    "        trigram_counter[(w1, w2, w3)] += 1\n",
    "print(tabulate(trigram_counter.most_common(n=10), headers = [\"Trigram\", \"Count\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How are the most common unigrams, bigrams, and trigrams different? (e.g. how many times does the top unigram appear in the top bigrams, the top trigrams?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting N-grams\n",
    "It's cool to be able to find the most common n-grams. Remember that the core principle behind language models is predicting the probability of a word given its context. In n-gram language models, we assume that the \"context\" is the last $n-1$ words. Therefore, we want to find the distribution: $P(W_k|W_{k-1} = w_{k-1}, W_{k-2} = w_{k-2}, ..., W_{k-n+1} = w_{k-n+1})$. For a trigram language model, this means: $P(W_k|W_{k-1} = w_{k-1}, W_{k-2} = w_{k-2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to do this well, we'll need to store our trigrams slightly differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_lm_counter = defaultdict(Counter)\n",
    "for sentence in tokenized_sentences:\n",
    "    for w1, w2, w3 in ngrams(sentence, 3, pad_right=True, pad_left=True, \n",
    "                             left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END):\n",
    "        trigram_lm_counter[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily start answering more interesting questions, such as: what are the most common words that start a sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word      count\n",
      "------  -------\n",
      "the        6035\n",
      "``         3655\n",
      "he         2725\n",
      "it         1913\n",
      "in         1617\n",
      "i          1328\n",
      "#          1254\n",
      "but        1219\n",
      "this       1047\n",
      "a           957\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(trigram_lm_counter[(SENTENCE_BEGIN, SENTENCE_BEGIN)].most_common(n = 10), headers = ['word', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some math, we can convert this into a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word        count\n",
      "------  ---------\n",
      "the     0.120128\n",
      "``      0.0727537\n",
      "he      0.0542418\n",
      "it      0.0380787\n",
      "in      0.0321868\n",
      "i       0.0264342\n",
      "#       0.0249612\n",
      "but     0.0242645\n",
      "this    0.0208408\n",
      "a       0.0190493\n"
     ]
    }
   ],
   "source": [
    "def get_prob_dist_from_counter(counter):\n",
    "    total_counts = sum([count for word, count in counter.items()])\n",
    "    return {word: count/total_counts for word, count in counter.items()}\n",
    "sentence_begin_distribution = get_prob_dist_from_counter(trigram_lm_counter[(SENTENCE_BEGIN, SENTENCE_BEGIN)])\n",
    "\n",
    "# show top distributions\n",
    "print(tabulate(sorted(sentence_begin_distribution.items(), key=lambda x: x[1], reverse=True)[0:10], headers = ['word', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the most common words that come after \"the blue\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mosque', 4),\n",
       " ('ridge', 3),\n",
       " ('of', 3),\n",
       " ('and', 2),\n",
       " ('room', 2),\n",
       " ('sky', 2),\n",
       " ('rug', 2),\n",
       " ('laws', 1),\n",
       " ('book', 1),\n",
       " ('jay', 1)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "trigram_lm_counter[('the', 'blue')].most_common(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many times does \"the sky blue\" appear?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "trigram_lm_counter[('the', 'sky')]['blue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability \"sky\" comes after \"the blue\" ($P(W_n=\"sky\"|W_{n-1}=\"blue\", W_{n-2}=\"the\")$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06060606060606061"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "get_prob_dist_from_counter(trigram_lm_counter[('the', 'blue')])['sky']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating N-grams! Making the Language Model speak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this counts data structure, we now have a rudimentary n-gram model! We can start using this to generate random sentences by repeatedly computing $P(W_k|W_{k-1} = w_{k-1}, W_{k-2} = w_{k-2})$ and then selecting a word at random from that distribution, and repeating until we get a ``</s>`` token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play around with the random seed and see what other sentences it makes!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play around with the random seed and see what other sentences it makes!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generation Method 1** - Random Seed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and early post-war periods .'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_next_word(counter, ngram):\n",
    "    counts = counter[ngram]\n",
    "    total_count = sum([count for word, count in counts.items()])\n",
    "    probabilities = [count/total_count for word,count in counts.items()]\n",
    "    vocabulary = [word for word,count in counts.items()]\n",
    "    return np.random.choice(vocabulary, 1, p=probabilities)[0]\n",
    "\n",
    "def generate_random_sentence(seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    sentence = []\n",
    "    bigram = (SENTENCE_BEGIN, SENTENCE_BEGIN)\n",
    "    next_word = get_random_next_word(trigram_lm_counter, bigram)\n",
    "    while next_word != SENTENCE_END:\n",
    "        # update the history\n",
    "        bigram = (bigram[1], next_word)\n",
    "\n",
    "        # append the word to the sentence\n",
    "        sentence.append(next_word)\n",
    "\n",
    "        # get the next word\n",
    "        next_word = get_random_next_word(trigram_lm_counter, bigram)\n",
    "    return sentence\n",
    "generated_sentence = generate_random_sentence(5)\n",
    "' '.join(generated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play around with the random seed and see what other sentences it makes!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generation Method 2** - Greedy Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are not going to pick randomly one word from the probability distribution. Instead we are going to follow a greedy approach. For each word we will keep picking the most prob word given the past bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first time in the world .\n"
     ]
    }
   ],
   "source": [
    "word = 'the'\n",
    "bigram = ('<s>', word)\n",
    "sentence = [start_bigram[0], start_bigram[1]]\n",
    "while word != '.':\n",
    "    word = trigram_lm_counter[bigram].most_common(1)[0][0]\n",
    "    sentence.append(word)\n",
    "    bigram = (bigram[1], word)\n",
    "print(\" \".join(sentence[1:]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you think is wrong in this approach?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-gram Language Models\n",
    "Now that we've walked through a basic example of constructing and using  our language model, there's no need to reinvent the wheel--let's take advantage of with [nltk's implementation of ngram language models](https://www.nltk.org/api/nltk.lm.html). Behind the scenes they basically do what we did above as well as some additional bells and whistles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "n = 3 # let's create an ngram language model with 3-grams\n",
    "lm_trigram = MLE(n) \n",
    "len(lm_trigram.vocab) # we have no words in our vocabulary yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add some data. To do this, we'll call [padded_everygram_pipeline](https://www.nltk.org/api/nltk.lm.html#nltk.lm.preprocessing.padded_everygram_pipeline) from nltk to get the data into a form that is LanguageModel friendly. TODO: possibly go into what the format of this data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, text_vocab = padded_everygram_pipeline(n, tokenized_sentences)\n",
    "lm_trigram.fit(train_text, vocabulary_text=text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50515"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_trigram.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using ``lm_trigram``, again answer: what are the most common words that come after \"the blue\"? Your answer should be the same as above.**\n",
    "\n",
    "**(hint: look at ``lm_trigram.counts``)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mosque', 4),\n",
       " ('of', 3),\n",
       " ('ridge', 3),\n",
       " ('sky', 2),\n",
       " ('and', 2),\n",
       " ('rug', 2),\n",
       " ('room', 2),\n",
       " ('jay', 1),\n",
       " ('chair', 1),\n",
       " ('lights', 1)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "lm_trigram.counts[('the', 'blue')].most_common(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate random sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'making such specialization possible .'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = lm_trigram.generate(100, random_seed=5)\n",
    "' '.join([t for t in tokens if t != '</s>']) # we should remove the '</s>' tokens just to keep it clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute probabilities like before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(W_n = \"the\")$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0505952488627212"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(w_n = \"blue\" | w_{n-1} = \"the\")$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004719409644757165"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('blue', ['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(w_n = \"sky\" | w_{n-1} = \"blue\", w_{n-2} = \"the\")$. Note that the probability below is the same as what we computed before as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06060606060606061"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('sky', ['the', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final note is that it's common to use log-probabilities to avoid floating-point inaccuracies with really low numbers. $log(P(w_n = \"sky\" | w_{n-1} = \"blue\", w_{n-2} = \"the\"))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.044394119358453"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.logscore('sky', ['the', 'blue']) # log(P(w3 == \"sky\" | w2 == \"blue\" && w1 == \"the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1431.098498997014"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [('<s>',),('<s>',),('the',),('fulton',),('county',),('grand',),('jury',),('said',),('friday',)]\n",
    "lm_trigram.perplexity(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.482907257302543"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.entropy(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability of seeing the trigram \"blue sky is\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('is', ['blue', 'sky'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One disadvantage of our current model is that there will be many n-grams we haven't seen before (e.g. \"blue sky is\"). Though \"blue sky is\" is a reasonable trigram, the probability assigned to it is 0. \n",
    "\n",
    "To account for this, we can try to \"smooth\" the data. In essence, smoothing is giving a very small, but non-zero probability to n-grams we have not seen before. The assumption here is that though we have not seen a particular n-gram before, it doesn't mean it has no chance of occurring. [These slides](https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf) have a good description of the various smoothing methods, and [this paper](https://www.aclweb.org/anthology/P96-1041.pdf) for an interesting analysis of the empirical performance of various smoothing methods.\n",
    "\n",
    "nltk has a couple methods implemented. We'll start with LaPlace Smoothing, which adds one to the count of each n-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace, KneserNeyInterpolated, WittenBellInterpolated, Lidstone\n",
    "\n",
    "n = 3\n",
    "lm_trigram_laplace = Laplace(n) # we'll start with LaPlace smoothing\n",
    "train_text, text_vocab = padded_everygram_pipeline(n, tokenized_sentences) # these are generators, so you'll need to make them each time\n",
    "lm_trigram_laplace.fit(train_text, vocabulary_text=text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_trigram_laplace.vocab) == len(lm_trigram.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability $P(W_n=\"sky\"|W_{n-1}=\"blue\", W_{n-2}=\"the\")$ under LaPlace smoothing? Is it smaller or greater than the probability without LaPlace smoothing?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9349529160401997e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "print(lm_trigram_laplace.score('sky', ['the', 'blue']))\n",
    "lm_trigram_laplace.score('sky', ['the', 'blue']) < lm_trigram.score('sky', ['the', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability of the trigram \"blue sky is\" now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9794532750054437e-05"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "lm_trigram_laplace.score('is', ['blue', 'sky'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you try running `generate` with `lm_trigram_laplace`, you'll notice that it takes a very long time to finish (we haven't gotten it to finish yet). Can you think of why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-b687d4e98d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate is taking a lot longer here. Why do you think this is the case?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_trigram_laplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'</s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we should remove the '</s>' tokens just to keep it clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             return _weighted_choice(\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# build up text one word at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             return _weighted_choice(\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# build up text one word at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m    142\u001b[0m         return self.unmasked_score(\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/models.py\u001b[0m in \u001b[0;36munmasked_score\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mnorm_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnorm_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"Computing size of vocabulary reflects the cutoff.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"Computing size of vocabulary reflects the cutoff.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    222\u001b[0m         vocabulary.\"\"\"\n\u001b[1;32m    223\u001b[0m         return chain(\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generate is taking a lot longer here. Why do you think this is the case?\n",
    "tokens = lm_trigram_laplace.generate(1, random_seed=20)\n",
    "' '.join([t for t in tokens if t != '</s>']) # we should remove the '</s>' tokens just to keep it clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does the quality of your sentences change with n-gram length? dataset size?\n",
    "2. Before, we focused just on producing sentences at a time. Can you modify the code to produce a paragraph at a time?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
