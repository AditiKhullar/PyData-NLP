{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Tutorial\n",
    "\n",
    "**Instructions**: \n",
    "In this tutorial, we will be creating an **n-gram language model** from scratch and using the language model in a variety of applications. \n",
    "\n",
    "Throughout this notebook, there will be a few **bolded** questions. These are questions for you to think about, and perhaps write some code to answer as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, let's import a set of libraries we will find useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aditi_khullar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "# for manipulating data\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# useful nlp methods\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "nltk.download('punkt')\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# downloading data\n",
    "from urllib import request\n",
    "\n",
    "# a function to flatten a list\n",
    "flatten_list = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Data\n",
    "To start, we'll be working with the [Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus), a collection of English-language texts from 500 different sources grouped in 15 different categories.(e.g. fiction, news, ... etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.sls.hawaii.edu/bley-vroman/brown_nolines.txt'\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Fulton County Grand Jury said Friday an investigation of Atlanta\\'s recent primary election produced \"no evidence\" that any irregularities took place.   \\r\\nThe jury further said in term-end presentments that the City Executive Committee, which had over-all charge of the election, \"deserves the praise and thanks of the City of Atlanta\" for the manner in which the election was conducted.\\r\\n\\r\\nThe Se'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[0:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains a set of newline-separated (\"\\r\\n\") sentences. In addition, on manual observation, we notice some lines are not broken into sentences perfectly. We will also split on \". \" as a crude way of catching these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Example line with multiple sentences--\n",
      "There has been more activity across the state line in Massachusetts than in Rhode Island in recent weeks toward enforcement of the Sunday sales laws. The statutes, similar in both the Bay State and Rhode Island and dating back in some instances to colonial times, severely limit the types of merchandise that may be sold on the Sabbath.   \n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced \"no evidence\" that any irregularities took place.\n",
      ">> sentence 1:   \n",
      ">> sentence 2: The jury further said in term-end presentments that the City Executive Committee, which had over-all charge of the election, \"deserves the praise and thanks of the City of Atlanta\" for the manner in which the election was conducted.\n",
      ">> sentence 3: \n",
      ">> sentence 4: The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible \"irregularities\" in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr&.\n"
     ]
    }
   ],
   "source": [
    "raw_sentences = raw.split('\\r\\n') # split by newline\n",
    "print('--Example line with multiple sentences--')\n",
    "print(raw_sentences[400]) # example line with a period in it\n",
    "\n",
    "raw_sentences = [re.split(r'(?<=\\.) ', sentence) for sentence in raw_sentences] # split by \". \"\n",
    "raw_sentences = flatten_list(raw_sentences)\n",
    "\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "     print('>> sentence {}:'.format(i), raw_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we note two things:\n",
    "\n",
    "1. Some sentences are blank (e.g. sentences 1 and 3). We'll want to remove those.\n",
    "2. Some words are capitalized while others are not. Some are proper nouns while others are the beginning of sentences. To help standardize this, let's lowercase all of the words (e.g. \"Only\" at the beginning of a sentence and \"only\" in the middle of a sentence are still the same).\n",
    "\n",
    "In order to build a language model. We also need to be able to split a sentence into words. Thankfully, there's a function from nltk called word_tokenize that can do this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 50238 sentences in total.\n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: ['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "\n",
      ">> sentence 1: ['the', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']\n",
      "\n",
      ">> sentence 2: ['the', 'september-october', 'term', 'jury', 'had', 'been', 'charged', 'by', 'fulton', 'superior', 'court', 'judge', 'durwood', 'pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'mayor-nominate', 'ivan', 'allen', 'jr', '&', '.']\n",
      "\n",
      ">> sentence 3: ['``', 'only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.']\n",
      "\n",
      ">> sentence 4: ['the', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', 'georgia', \"'s\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(s):\n",
    "    # remove trailing whitespace\n",
    "    s = s.strip()\n",
    "    \n",
    "    # lowercase all tokens\n",
    "    s = s.lower()\n",
    "    \n",
    "    # split into tokens - TODO: this requires installing \"punkt\". Perhaps we should make a version that doesn't require installing anything\n",
    "    s = word_tokenize(s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "# preprocess each sentence and also remove empty sentences\n",
    "tokenized_sentences = [preprocess_sentence(s) for s in raw_sentences]\n",
    "tokenized_sentences = [s for s in tokenized_sentences if len(s) > 0]\n",
    "\n",
    "# print sample sentences\n",
    "print('We have {} sentences in total.'.format(len(tokenized_sentences)))\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "    print('>> sentence {}:'.format(i), tokenized_sentences[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is starting to look good. Again we'll point out a few things:\n",
    "\n",
    "1. Punctuation are their own tokens. Sometimes we will also choose to remove punctuation completely from our sentences. In . this example, we'll keep it for simplicity. \n",
    "2. As we'll see in the section below, tokenizing our sentences in this way makes it really easy to count n-grams moving forward.\n",
    "\n",
    "Note that you can also work with the **brown corpus available in the nltk library**. Above we started by using the raw corpus. NLTK pprovides you a handle on the words and sentences direcly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "#words\n",
    "nltk_words = brown.words()\n",
    "#sentences\n",
    "nltk_sents = brown.sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the various categories covered in Brown corpus. It will be interesting to note how the language model you create changes when you limit the underlying dataset to only couple of these categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sents = brown.sents(categories=['news', 'editorial', 'reviews'])\n",
    "#words\n",
    "nltk_words = brown.words(categories=['news', 'editorial', 'reviews'])\n",
    "#sentences\n",
    "nltk_sents = brown.sents(categories=['news', 'editorial', 'reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a languge model on Macbeth's script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "macbeth_words = gutenberg.words('shakespeare-macbeth.txt')\n",
    "macbeth_sents = gutenberg.sents('shakespeare-macbeth.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']'], ['Actus', 'Primus', '.'], ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macbeth_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into counting n=grams, let's do something a little simpler. What are the most common words (or \"unigrams\") in our corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 69924),\n",
       " (',', 58328),\n",
       " ('.', 48646),\n",
       " ('of', 36406),\n",
       " ('and', 28834),\n",
       " ('to', 26095),\n",
       " ('a', 23370),\n",
       " ('in', 21335),\n",
       " ('that', 10773),\n",
       " ('is', 10191)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "        word_counter[word] += 1\n",
    "word_counter.most_common(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one might expect, we see words like \"the\", \"of\", \"and\"... etc. We can also plot this to see the relative frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gather the data\n",
    "most_common_words = word_counter.most_common(n=50)\n",
    "indexes = np.arange(len(most_common_words))\n",
    "labels = [l for l,v in most_common_words]\n",
    "values = [v for l,v in most_common_words]\n",
    "\n",
    "# create the plot\n",
    "width = 1\n",
    "plt.rcParams['figure.figsize'] = [20, 5]\n",
    "plt.bar(indexes, values, width)\n",
    "plt.xticks(indexes, labels)\n",
    "plt.title('Most common words in the Brown Corpus')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows a phenomenon commonly known as [Zipf's law](https://nlp.stanford.edu/IR-book/html/htmledition/zipfs-law-modeling-the-distribution-of-terms-1.html), which basically says that the most common words show up exponentially more often than less common words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk conveniently provides functions to help us find the n-grams in a sentence. In the output of the cell below, you'll also notice that the beginning and ending n-grams are padded with ``<s>`` and ``</s>``. We can see these tokens as a special \"word\" that marks the beginning and end of sentences. This helps us use an n-gram even when computing probabilities for the first word of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--10 sample bigrams--\n",
      "<s> the\n",
      "the fulton\n",
      "fulton county\n",
      "county grand\n",
      "grand jury\n",
      "...\n",
      "any irregularities\n",
      "irregularities took\n",
      "took place\n",
      "place .\n",
      ". <\\s>\n",
      "\n",
      "--10 sample trigrams--\n",
      "<s> <s> the\n",
      "<s> the fulton\n",
      "the fulton county\n",
      "fulton county grand\n",
      "county grand jury\n",
      "...\n",
      "any irregularities took\n",
      "irregularities took place\n",
      "took place .\n",
      "place . <\\s>\n",
      ". <\\s> <\\s>\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_BEGIN = '<s>'\n",
    "SENTENCE_END = '<\\s>'\n",
    "sentence_0_bigrams = ngrams(tokenized_sentences[0], 2, pad_right=True, pad_left=True, \n",
    "                            left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END)\n",
    "sentence_0_trigrams = ngrams(tokenized_sentences[0], 3, pad_right=True, pad_left=True, \n",
    "                             left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END)\n",
    "sentence_0_bigrams = list(sentence_0_bigrams)\n",
    "sentence_0_trigrams = list(sentence_0_trigrams)\n",
    "\n",
    "# extra code to print the n-grams more nicely\n",
    "print('--10 sample bigrams--')\n",
    "for w1, w2 in sentence_0_bigrams[0:5]:\n",
    "    print(w1, w2)\n",
    "print('...')\n",
    "for w1, w2 in sentence_0_bigrams[-5:]:\n",
    "    print(w1, w2)\n",
    "print()\n",
    "print('--10 sample trigrams--')\n",
    "for w1, w2, w3 in sentence_0_trigrams[0:5]:\n",
    "    print(w1, w2, w3)\n",
    "print('...')\n",
    "for w1, w2, w3 in sentence_0_trigrams[-5:]:\n",
    "    print(w1, w2, w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we can count trigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for w1, w2, w3 in ngrams(sentence, 3, pad_right=True, pad_left=True, \n",
    "                             left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END):\n",
    "        trigram_counter[(w1, w2, w3)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the most common trigrams? Do any of them surprise you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('.', '<\\\\s>', '<\\\\s>'), 48453),\n",
       " (('<s>', '<s>', 'the'), 6035),\n",
       " (('<s>', '<s>', '``'), 3655),\n",
       " ((\"''\", '.', '<\\\\s>'), 3360),\n",
       " (('<s>', '<s>', 'he'), 2725),\n",
       " (('<s>', '<s>', 'it'), 1913),\n",
       " (('<s>', '<s>', 'in'), 1617),\n",
       " (('<s>', '<s>', 'i'), 1328),\n",
       " (('#', '<\\\\s>', '<\\\\s>'), 1265),\n",
       " (('<s>', '<s>', '#'), 1254)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "trigram_counter.most_common(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How about the most common bigrams?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('.', '<\\\\s>'), 48453),\n",
       " (('of', 'the'), 9702),\n",
       " ((',', 'and'), 6272),\n",
       " (('<s>', 'the'), 6035),\n",
       " (('in', 'the'), 5996),\n",
       " ((',', 'the'), 3749),\n",
       " (('<s>', '``'), 3655),\n",
       " (('to', 'the'), 3439),\n",
       " ((\"''\", '.'), 3375),\n",
       " (('<s>', 'he'), 2725)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "bigram_counter = Counter()\n",
    "for sentence in tokenized_sentences:\n",
    "    for w1, w2 in ngrams(sentence, 2, pad_right=True, pad_left=True, \n",
    "                             left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END):\n",
    "        bigram_counter[(w1, w2)] += 1\n",
    "bigram_counter.most_common(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How are the most common unigrams, bigrams, and trigrams different? (e.g. how many times does the top unigram appear in the top bigrams, the top trigrams?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting n-grams\n",
    "It's cool to be able to find the most common n-grams. Remember that the core principle behind language models is predicting the probability of a word given its context. In n-gram language models, we assume that the \"context\" is the last $n-1$ words. Therefore, we want to find the distribution: $P(W_k|W_{k-1} = w_{k-1}, W_{k-2} = w_{k-2}, ..., W_{k-n+1} = w_{k-n+1})$. For a trigram language model, this means: $P(W_k|W_{k-1} = w_{k-1}, W_{k-2} = w_{k-2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to do this well, we'll need to store our trigrams slightly differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_lm_counter = defaultdict(Counter)\n",
    "for sentence in tokenized_sentences:\n",
    "    for w1, w2, w3 in ngrams(sentence, 3, pad_right=True, pad_left=True, \n",
    "                             left_pad_symbol=SENTENCE_BEGIN, right_pad_symbol=SENTENCE_END):\n",
    "        trigram_lm_counter[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can easily start answering more interesting questions, such as: what are the most common words that start a sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 6035),\n",
       " ('``', 3655),\n",
       " ('he', 2725),\n",
       " ('it', 1913),\n",
       " ('in', 1617),\n",
       " ('i', 1328),\n",
       " ('#', 1254),\n",
       " ('but', 1219),\n",
       " ('this', 1047),\n",
       " ('a', 957)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_lm_counter[(SENTENCE_BEGIN, SENTENCE_BEGIN)].most_common(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some math, we can convert this into a probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.12012818981647358),\n",
       " ('``', 0.07275369242406146),\n",
       " ('he', 0.054241808989211354),\n",
       " ('it', 0.03807874517297663),\n",
       " ('in', 0.03218679087543294),\n",
       " ('i', 0.026434173334925752),\n",
       " ('#', 0.02496118476053983),\n",
       " ('but', 0.0242645009753573),\n",
       " ('this', 0.02084079780246029),\n",
       " ('a', 0.019049325211990924)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prob_dist_from_counter(counter):\n",
    "    total_counts = sum([count for word, count in counter.items()])\n",
    "    return {word: count/total_counts for word, count in counter.items()}\n",
    "sentence_begin_distribution = get_prob_dist_from_counter(trigram_lm_counter[(SENTENCE_BEGIN, SENTENCE_BEGIN)])\n",
    "\n",
    "# show top distributions\n",
    "sorted(sentence_begin_distribution.items(), key=lambda x: x[1], reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the most common words that come after \"the blue\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mosque', 4),\n",
       " ('ridge', 3),\n",
       " ('of', 3),\n",
       " ('and', 2),\n",
       " ('room', 2),\n",
       " ('sky', 2),\n",
       " ('rug', 2),\n",
       " ('laws', 1),\n",
       " ('book', 1),\n",
       " ('jay', 1)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "trigram_lm_counter[('the', 'blue')].most_common(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many times does \"the blue sky\" appear?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "trigram_lm_counter[('the', 'blue')]['sky']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many times does \"the sky blue\" appear?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "trigram_lm_counter[('the', 'sky')]['blue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability \"sky\" comes after \"the blue\" ($P(W_n=\"sky\"|W_{n-1}=\"blue\", W_{n-2}=\"the\")$)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06060606060606061"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "get_prob_dist_from_counter(trigram_lm_counter[('the', 'blue')])['sky']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this counts data structure, we now have a rudimentary n-gram model! We can start using this to generate random sentences by repeatedly computing $P(W_k|W_{k-1} = w_{k-1}, W_{k-2} = w_{k-2})$ and then selecting a word at random from that distribution, and repeating until we get a ``</s>`` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it seemed to understand .'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_next_word(counter, ngram):\n",
    "    counts = counter[ngram]\n",
    "    total_count = sum([count for word, count in counts.items()])\n",
    "    probabilities = [count/total_count for word,count in counts.items()]\n",
    "    vocabulary = [word for word,count in counts.items()]\n",
    "    return np.random.choice(vocabulary, 1, p=probabilities)[0]\n",
    "\n",
    "def generate_random_sentence(seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    sentence = []\n",
    "    bigram = (SENTENCE_BEGIN, SENTENCE_BEGIN)\n",
    "    next_word = get_random_next_word(trigram_lm_counter, bigram)\n",
    "    while next_word != SENTENCE_END:\n",
    "        # update the history\n",
    "        bigram = (bigram[1], next_word)\n",
    "\n",
    "        # append the word to the sentence\n",
    "        sentence.append(next_word)\n",
    "\n",
    "        # get the next word\n",
    "        next_word = get_random_next_word(trigram_lm_counter, bigram)\n",
    "    return sentence\n",
    "generated_sentence = generate_random_sentence(5)\n",
    "' '.join(generated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play around with the random seed and see what other sentences it makes!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram Language Models\n",
    "Now that we've walked through a basic example of constructing and using  our language model, there's no need to reinvent the wheel--let's take advantage of with [nltk's implementation of ngram language models](https://www.nltk.org/api/nltk.lm.html). Behind the scenes they basically do what we did above as well as some additional bells and whistles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.lm import MLE\n",
    "\n",
    "n = 3 # let's create an ngram language model with 3-grams\n",
    "lm_trigram = MLE(n) \n",
    "len(lm_trigram.vocab) # we have no words in our vocabulary yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add some data. To do this, we'll call [padded_everygram_pipeline](https://www.nltk.org/api/nltk.lm.html#nltk.lm.preprocessing.padded_everygram_pipeline) from nltk to get the data into a form that is LanguageModel friendly. TODO: possibly go into what the format of this data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, text_vocab = padded_everygram_pipeline(n, tokenized_sentences)\n",
    "lm_trigram.fit(train_text, vocabulary_text=text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50515"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_trigram.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using ``lm_trigram``, again answer: what are the most common words that come after \"the blue\"? Your answer should be the same as above.**\n",
    "\n",
    "**(hint: look at ``lm_trigram.counts``)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mosque', 4),\n",
       " ('ridge', 3),\n",
       " ('of', 3),\n",
       " ('and', 2),\n",
       " ('room', 2),\n",
       " ('sky', 2),\n",
       " ('rug', 2),\n",
       " ('laws', 1),\n",
       " ('book', 1),\n",
       " ('jay', 1)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "lm_trigram.counts[('the', 'blue')].most_common(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate random sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'making such specialization possible .'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = lm_trigram.generate(100, random_seed=5)\n",
    "' '.join([t for t in tokens if t != '</s>']) # we should remove the '</s>' tokens just to keep it clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute probabilities like before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(W_n = \"the\")$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0505952488627212"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(w_n = \"blue\" | w_{n-1} = \"the\")$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004719409644757165"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('blue', ['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(w_n = \"sky\" | w_{n-1} = \"blue\", w_{n-2} = \"the\")$. Note that the probability below is the same as what we computed before as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06060606060606061"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('sky', ['the', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final note is that it's common to use log-probabilities to avoid floating-point inaccuracies with really low numbers. $log(P(w_n = \"sky\" | w_{n-1} = \"blue\", w_{n-2} = \"the\"))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.044394119358453"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.logscore('sky', ['the', 'blue']) # log(P(w3 == \"sky\" | w2 == \"blue\" && w1 == \"the\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "perplexity() missing 1 required positional argument: 'text_ngrams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-1bca1206e925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlm_trigram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: perplexity() missing 1 required positional argument: 'text_ngrams'"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "lm_trigram.perplexity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability of seeing the trigram \"blue sky is\"?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_trigram.score('is', ['blue', 'sky'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One disadvantage of our current model is that there will be many n-grams we haven't seen before (e.g. \"blue sky is\"). Though \"blue sky is\" is a reasonable trigram, the probability assigned to it is 0. \n",
    "\n",
    "To account for this, we can try to \"smooth\" the data. In essence, smoothing is giving a very small, but non-zero probability to n-grams we have not seen before. The assumption here is that though we have not seen a particular n-gram before, it doesn't mean it has no chance of occurring. [These slides](https://nlp.stanford.edu/~wcmac/papers/20050421-smoothing-tutorial.pdf) have a good description of the various smoothing methods, and [this paper](https://www.aclweb.org/anthology/P96-1041.pdf) for an interesting analysis of the empirical performance of various smoothing methods.\n",
    "\n",
    "nltk has a couple methods implemented. We'll start with LaPlace Smoothing, which adds one to the count of each n-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace, KneserNeyInterpolated, WittenBellInterpolated, Lidstone\n",
    "\n",
    "n = 3\n",
    "lm_trigram_laplace = Laplace(n) # we'll start with LaPlace smoothing\n",
    "train_text, text_vocab = padded_everygram_pipeline(n, tokenized_sentences) # these are generators, so you'll need to make them each time\n",
    "lm_trigram_laplace.fit(train_text, vocabulary_text=text_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_trigram_laplace.vocab) == len(lm_trigram.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability $P(W_n=\"sky\"|W_{n-1}=\"blue\", W_{n-2}=\"the\")$ under LaPlace smoothing? Is it smaller or greater than the probability without LaPlace smoothing?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9349529160401997e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "print(lm_trigram_laplace.score('sky', ['the', 'blue']))\n",
    "lm_trigram_laplace.score('sky', ['the', 'blue']) < lm_trigram.score('sky', ['the', 'blue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the probability of the trigram \"blue sky is\" now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9794532750054437e-05"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: your code here\n",
    "lm_trigram_laplace.score('is', ['blue', 'sky'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you try running `generate` with `lm_trigram_laplace`, you'll notice that it takes a very long time to finish (we haven't gotten it to finish yet). Can you think of why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-b687d4e98d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate is taking a lot longer here. Why do you think this is the case?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm_trigram_laplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'</s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we should remove the '</s>' tokens just to keep it clean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             return _weighted_choice(\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# build up text one word at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             return _weighted_choice(\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# build up text one word at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/api.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m    142\u001b[0m         return self.unmasked_score(\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/models.py\u001b[0m in \u001b[0;36munmasked_score\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mword_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mnorm_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnorm_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"Computing size of vocabulary reflects the cutoff.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;34m\"\"\"Computing size of vocabulary reflects the cutoff.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.7/site-packages/nltk/lm/vocabulary.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    222\u001b[0m         vocabulary.\"\"\"\n\u001b[1;32m    223\u001b[0m         return chain(\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generate is taking a lot longer here. Why do you think this is the case?\n",
    "tokens = lm_trigram_laplace.generate(1, random_seed=20)\n",
    "' '.join([t for t in tokens if t != '</s>']) # we should remove the '</s>' tokens just to keep it clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does the quality of your sentences change with n-gram length? dataset size?\n",
    "2. Before, we focused just on producing sentences at a time. Can you modify the code to produce a paragraph at a time?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
