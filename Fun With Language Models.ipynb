{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Getting-Started\" data-toc-modified-id=\"Getting-Started-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Getting Started</a></span></li><li><span><a href=\"#N-gram-Length\" data-toc-modified-id=\"N-gram-Length-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>N-gram Length</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Shakespeare\" data-toc-modified-id=\"Shakespeare-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Shakespeare</a></span></li><li><span><a href=\"#Wine-Reviews\" data-toc-modified-id=\"Wine-Reviews-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Wine Reviews</a></span></li><li><span><a href=\"#Try-Your-Own!\" data-toc-modified-id=\"Try-Your-Own!-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Try Your Own!</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created and interacted with some language models, let's have some fun! Note: before going through this, I would recommend going through the \"Language Model Tutorial\" first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's import a set of libraries we'll find useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/eugenetang/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/eugenetang/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     /Users/eugenetang/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "# for manipulating data\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# useful nlp methods\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "fbrown nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE, Laplace\n",
    "\n",
    "# download some datasets\n",
    "nltk.download('brown')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('webtext')\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# printing\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a few useful constants and functions that will be useful later. They should be familiar from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_BEGIN = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def pretty_print_tuples(tuples, headers):\n",
    "    '''Pretty print tuples using tabulate.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples: list[tuple[str]]\n",
    "        a list of tuples; each tuple must have the same dimensions\n",
    "    headers: list[str]\n",
    "        a list of headers to use; this list must be the same size as the number of elements in each tuple\n",
    "\n",
    "    '''\n",
    "    table = [list(tup) for tup in tuples]\n",
    "    print(tabulate(table, headers = headers, floatfmt=\".5f\"))\n",
    "\n",
    "\n",
    "def print_top_unigrams(sentences, n, remove_stopwords_and_punc):\n",
    "    '''Print the top n unigrams in the sentences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: list[list[str]]\n",
    "        a list of tokenized sentences\n",
    "    n: int\n",
    "        the number of unigrams to print\n",
    "    remove_stopwords_and_punc: bool\n",
    "        whether to remove stopwords and punctuation from list of unigrams\n",
    "\n",
    "    '''\n",
    "    unigram_counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if not remove_stopwords_and_punc or (word.lower() not in STOPWORDS and word.isalpha()):\n",
    "                unigram_counter[word] += 1\n",
    "    print('Our dataset has {} unique words.'.format(len(unigram_counter)))\n",
    "    print()\n",
    "    print('--Top 10 Unigrams--')\n",
    "    print()\n",
    "    pretty_print_tuples(unigram_counter.most_common(n=n), ['Unigram', 'Count'])\n",
    "    \n",
    "def generate_sentence(lm, text_seed, random_seed=None):\n",
    "    '''Generate a random sentence from the given language model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lm: nltk.LanguageModel\n",
    "        an nltk language model object\n",
    "    text_seed: [str]\n",
    "        a list of strings to seed the sentence with\n",
    "    random_seed: int\n",
    "        an integer seed for the randomization\n",
    "    '''\n",
    "    tokens = lm.generate(50, text_seed=text_seed, random_seed=random_seed)\n",
    "\n",
    "    # just take the first sentence\n",
    "    sentence = [] if text_seed is None else text_seed\n",
    "    for t in tokens:\n",
    "        if t == SENTENCE_END:\n",
    "            break\n",
    "        sentence.append(t)\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some n-gram models of varying lengths and see how it affects the quality of the generated sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train various n-gram models. This cell takes a few minutes to run\n",
    "from nltk.corpus import brown\n",
    "fiction_sentences = brown.sents(categories=['fiction', 'science_fiction'])\n",
    "def train_ngram_language_model(n):\n",
    "    '''Train an n-gram language model on the fiction brown corpus.'''\n",
    "    lm = MLE(n)\n",
    "    train_text, text_vocab = padded_everygram_pipeline(n, fiction_sentences)\n",
    "    lm.fit(train_text, vocabulary_text=text_vocab)\n",
    "    return lm\n",
    "lm_unigram = train_ngram_language_model(1)\n",
    "lm_bigram = train_ngram_language_model(2)\n",
    "lm_trigram = train_ngram_language_model(3)\n",
    "lm_fourgram = train_ngram_language_model(4)\n",
    "lm_fivegram = train_ngram_language_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Sample Unigram Language Model Sentences---\n",
      "Sample 1: The To . consult Certain , county tune take should So his about He . Rameau us the that take Jesus and might receipt the this . listened of he Homemakers gesture . war their horizon and to intercept thought the he did left east Eugene and that , , metal\n",
      "Sample 2: The me room such was road uniform , four was no to . from `` his into '' Said across tried shouted Each support ? man : ! there Once Repeating within they along westerly his of Mrs. was one where to and blue Godwin And , and like ! of\n",
      "\n",
      "---Sample Bigram Language Model Sentences---\n",
      "Sample 1: The clock , drafting board .\n",
      "Sample 2: The mouth open on those two weeks .\n",
      "\n",
      "---Sample Trigram Language Model Sentences---\n",
      "Sample 1: The clock on the bench .\n",
      "Sample 2: The mouth was thin-lipped and wide lapels like a water brother when she meant no .\n",
      "\n",
      "---Sample Four-gram Language Model Sentences---\n",
      "Sample 1: The clock on the mantel piece was scandalized and ticked so loudly that he glanced at it over his shoulder .\n",
      "Sample 2: The mouth was thin-lipped and wide , the long cleft in the upper lip like a slide .\n",
      "\n",
      "---Sample Five-gram Language Model Sentences---\n",
      "Sample 1: The clock on the mantel piece was scandalized and ticked so loudly that he glanced at it over his shoulder and then quickly left the room .\n",
      "Sample 2: The mouth was thin-lipped and wide , the long cleft in the upper lip like a slide .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---Sample Unigram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_unigram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_unigram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Bigram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_bigram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_bigram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Trigram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_trigram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_trigram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Four-gram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_fourgram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_fourgram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Five-gram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_fivegram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_fivegram, ['The'], 5))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that once we get to longer and longer n-grams, the diversity of the sentences start to decrease. For example, if we wanted to find the word after \"The clock on the\", there are fewer options for what can follow \"The clock on the\" in a five-gram model versus \"on the\" in a trigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try training n-gram language models with different training data and see how the output changes. Conveniently, nltk provides us an interface to some additional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shakespeare\n",
    "Let's train our language model to produce Shakespeare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Julius Caeser\", \"Hamlet\", and \"Macbeth\" by Shakespeare have 7176 sentences.\n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: [ The Tragedie of Julius Caesar by William Shakespeare 1599 ]\n",
      ">> sentence 1: Actus Primus .\n",
      ">> sentence 2: Scoena Prima .\n",
      ">> sentence 3: Enter Flauius , Murellus , and certaine Commoners ouer the Stage .\n",
      ">> sentence 4: Flauius .\n",
      "\n",
      "Our dataset has 8729 unique words.\n",
      "\n",
      "--Top 10 Unigrams--\n",
      "\n",
      "Unigram      Count\n",
      "---------  -------\n",
      "haue           406\n",
      "Ham            337\n",
      "Lord           293\n",
      "shall          259\n",
      "thou           256\n",
      "King           231\n",
      "Enter          225\n",
      "Caesar         192\n",
      "vs             183\n",
      "thy            175\n"
     ]
    }
   ],
   "source": [
    "shakespeare_sentences = []\n",
    "for corpora in ['shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']:\n",
    "    shakespeare_sentences += list(nltk.corpus.gutenberg.sents(corpora))\n",
    "\n",
    "print('\"Julius Caeser\", \"Hamlet\", and \"Macbeth\" by Shakespeare have {} sentences.'.format(len(shakespeare_sentences)))\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "     print('>> sentence {}:'.format(i), ' '.join(shakespeare_sentences[i]))\n",
    "print()\n",
    "print_top_unigrams(shakespeare_sentences, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why are you aught That man may question ?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_shakespeare = MLE(3)\n",
    "train_text, text_vocab = padded_everygram_pipeline(3, shakespeare_sentences)\n",
    "lm_shakespeare.fit(train_text, vocabulary_text=text_vocab)\n",
    "generate_sentence(lm_shakespeare, ['Why'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Reviews\n",
    "For something a little different, let's look at some wine reviews too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wine review corpus has 2984 sentences.\n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: Lovely delicate , fragrant Rhone wine .\n",
      ">> sentence 1: Polished leather and strawberries .\n",
      ">> sentence 2: Perhaps a bit dilute , but good for drinking now .\n",
      ">> sentence 3: *** Liquorice , cherry fruit .\n",
      ">> sentence 4: Simple and coarse at the finish .\n",
      "\n",
      "Our dataset has 3121 unique words.\n",
      "\n",
      "--Top 10 Unigrams--\n",
      "\n",
      "Unigram      Count\n",
      "---------  -------\n",
      "fruit          296\n",
      "good           250\n",
      "wine           229\n",
      "bit            217\n",
      "quite          204\n",
      "Top            182\n",
      "nose           151\n",
      "touch          146\n",
      "Bare           133\n",
      "palate         121\n"
     ]
    }
   ],
   "source": [
    "wine_sentences = list(nltk.corpus.webtext.sents('wine.txt'))\n",
    "\n",
    "print('The wine review corpus has {} sentences.'.format(len(wine_sentences)))\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "     print('>> sentence {}:'.format(i), ' '.join(wine_sentences[i]))\n",
    "print()\n",
    "print_top_unigrams(wine_sentences, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Red Burgundy Wine as it approaches its 10th birthday .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_wine = MLE(3)\n",
    "train_text, text_vocab = padded_everygram_pipeline(3, wine_sentences)\n",
    "lm_wine.fit(train_text, vocabulary_text=text_vocab)\n",
    "generate_sentence(lm_wine, ['Red'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Your Own!\n",
    "\n",
    "Go to https://www.nltk.org/book/ch02.html to find some fun corpora of your own! Train a language model and see what sentences come out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
