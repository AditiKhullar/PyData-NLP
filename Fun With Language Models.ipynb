{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Getting-Started\" data-toc-modified-id=\"Getting-Started-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Getting Started</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fiction\" data-toc-modified-id=\"Fiction-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Fiction</a></span></li><li><span><a href=\"#Shakespeare\" data-toc-modified-id=\"Shakespeare-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Shakespeare</a></span></li><li><span><a href=\"#Wine-Reviews\" data-toc-modified-id=\"Wine-Reviews-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Wine Reviews</a></span></li></ul></li><li><span><a href=\"#N-gram-Length\" data-toc-modified-id=\"N-gram-Length-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>N-gram Length</a></span></li><li><span><a href=\"#Dataset-Size\" data-toc-modified-id=\"Dataset-Size-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dataset Size</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created and interacted with some language models, let's have some fun exploring some other parameters! Note: before going through this, I would recommend going through the \"Language Model Tutorial\" first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's import a set of libraries we'll find useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/eugenetang/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/eugenetang/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     /Users/eugenetang/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "# for manipulating data\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# useful nlp methods\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE, Laplace\n",
    "\n",
    "# download some datasets\n",
    "nltk.download('brown')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('webtext')\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# printing\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a few useful constants and functions that will be useful later. They should be familiar from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_BEGIN = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def pretty_print_tuples(tuples, headers):\n",
    "    '''Pretty print tuples using tabulate.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tuples: list[tuple[str]]\n",
    "        a list of tuples; each tuple must have the same dimensions\n",
    "    headers: list[str]\n",
    "        a list of headers to use; this list must be the same size as the number of elements in each tuple\n",
    "\n",
    "    '''\n",
    "    table = [list(tup) for tup in tuples]\n",
    "    print(tabulate(table, headers = headers, floatfmt=\".5f\"))\n",
    "\n",
    "\n",
    "def print_top_unigrams(sentences, n, remove_stopwords_and_punc):\n",
    "    '''Print the top n unigrams in the sentences.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: list[list[str]]\n",
    "        a list of tokenized sentences\n",
    "    n: int\n",
    "        the number of unigrams to print\n",
    "    remove_stopwords_and_punc: bool\n",
    "        whether to remove stopwords and punctuation from list of unigrams\n",
    "\n",
    "    '''\n",
    "    unigram_counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if not remove_stopwords_and_punc or (word.lower() not in STOPWORDS and word.isalpha()):\n",
    "                unigram_counter[word] += 1\n",
    "    print('Our dataset has {} unique words.'.format(len(unigram_counter)))\n",
    "    print()\n",
    "    print('--Top 10 Unigrams--')\n",
    "    print()\n",
    "    pretty_print_tuples(unigram_counter.most_common(n=n), ['Unigram', 'Count'])\n",
    "    \n",
    "def generate_sentence(lm, text_seed, random_seed=None):\n",
    "    '''Generate a random sentence from the given language model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lm: nltk.LanguageModel\n",
    "        an nltk language model object\n",
    "    text_seed: [str]\n",
    "        a list of strings to seed the sentence with\n",
    "    random_seed: int\n",
    "        an integer seed for the randomization\n",
    "\n",
    "    '''\n",
    "    tokens = lm.generate(100, text_seed=text_seed, random_seed=random_seed)\n",
    "    # remove the sentence begin and end tokens to keep it clean\n",
    "    return ' '.join(text_seed + [t for t in tokens if t != SENTENCE_BEGIN and t != SENTENCE_END])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try training n-gram language models with different training data and see how the output changes. Conveniently, nltk provides us an interface to some additional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiction\n",
    "The Brown corpus has category labels for each document. Let's focus just on the fiction categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fiction and science_fiction categories have 5197 sentences.\n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: Thirty-three\n",
      ">> sentence 1: Scotty did not go back to school .\n",
      ">> sentence 2: His parents talked seriously and lengthily to their own doctor and to a specialist at the University Hospital -- Mr. McKinley was entitled to a discount for members of his family -- and it was decided it would be best for him to take the remainder of the term off , spend a lot of time in bed and , for the rest , do pretty much as he chose -- provided , of course , he chose to do nothing too exciting or too debilitating .\n",
      ">> sentence 3: His teacher and his school principal were conferred with and everyone agreed that , if he kept up with a certain amount of work at home , there was little danger of his losing a term .\n",
      ">> sentence 4: Scotty accepted the decision with indifference and did not enter the arguments .\n",
      "\n",
      "Our dataset has 9762 unique words.\n",
      "\n",
      "--Top 10 Unigrams--\n",
      "\n",
      "Unigram      Count\n",
      "---------  -------\n",
      "would          366\n",
      "said           233\n",
      "could          215\n",
      "one            204\n",
      "like           172\n",
      "time           129\n",
      "man            128\n",
      "back           121\n",
      "know           100\n",
      "came            99\n"
     ]
    }
   ],
   "source": [
    "fiction_sentences = brown.sents(categories=['fiction', 'science_fiction'])\n",
    "print('The fiction and science_fiction categories have {} sentences.'.format(len(fiction_sentences)))\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "     print('>> sentence {}:'.format(i), ' '.join(fiction_sentences[i]))\n",
    "print()\n",
    "print_top_unigrams(fiction_sentences, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Doctor It infuriated him .'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fiction = MLE(3)\n",
    "train_text, text_vocab = padded_everygram_pipeline(3, fiction_sentences)\n",
    "lm_fiction.fit(train_text, vocabulary_text=text_vocab)\n",
    "generate_sentence(lm_fiction, ['Doctor'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shakespeare\n",
    "Let's train our language model to produce Shakespeare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Julius Caeser\", \"Hamlet\", and \"Macbeth\" by Shakespeare have 7176 sentences.\n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: [ The Tragedie of Julius Caesar by William Shakespeare 1599 ]\n",
      ">> sentence 1: Actus Primus .\n",
      ">> sentence 2: Scoena Prima .\n",
      ">> sentence 3: Enter Flauius , Murellus , and certaine Commoners ouer the Stage .\n",
      ">> sentence 4: Flauius .\n",
      "\n",
      "Our dataset has 8729 unique words.\n",
      "\n",
      "--Top 10 Unigrams--\n",
      "\n",
      "Unigram      Count\n",
      "---------  -------\n",
      "haue           406\n",
      "Ham            337\n",
      "Lord           293\n",
      "shall          259\n",
      "thou           256\n",
      "King           231\n",
      "Enter          225\n",
      "Caesar         192\n",
      "vs             183\n",
      "thy            175\n"
     ]
    }
   ],
   "source": [
    "shakespeare_sentences = []\n",
    "for corpora in ['shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']:\n",
    "    shakespeare_sentences += list(nltk.corpus.gutenberg.sents(corpora))\n",
    "\n",
    "print('\"Julius Caeser\", \"Hamlet\", and \"Macbeth\" by Shakespeare have {} sentences.'.format(len(shakespeare_sentences)))\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "     print('>> sentence {}:'.format(i), ' '.join(shakespeare_sentences[i]))\n",
    "print()\n",
    "print_top_unigrams(shakespeare_sentences, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why are you aught That man may question ?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_shakespeare = MLE(3)\n",
    "train_text, text_vocab = padded_everygram_pipeline(3, shakespeare_sentences)\n",
    "lm_shakespeare.fit(train_text, vocabulary_text=text_vocab)\n",
    "generate_sentence(lm_shakespeare, ['Why'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Reviews\n",
    "For something a little different, let's look at some wine reviews too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wine review corpus has 2984 sentences.\n",
      "\n",
      "--Sample sentences--\n",
      ">> sentence 0: Lovely delicate , fragrant Rhone wine .\n",
      ">> sentence 1: Polished leather and strawberries .\n",
      ">> sentence 2: Perhaps a bit dilute , but good for drinking now .\n",
      ">> sentence 3: *** Liquorice , cherry fruit .\n",
      ">> sentence 4: Simple and coarse at the finish .\n",
      "\n",
      "Our dataset has 3121 unique words.\n",
      "\n",
      "--Top 10 Unigrams--\n",
      "\n",
      "Unigram      Count\n",
      "---------  -------\n",
      "fruit          296\n",
      "good           250\n",
      "wine           229\n",
      "bit            217\n",
      "quite          204\n",
      "Top            182\n",
      "nose           151\n",
      "touch          146\n",
      "Bare           133\n",
      "palate         121\n"
     ]
    }
   ],
   "source": [
    "wine_sentences = list(nltk.corpus.webtext.sents('wine.txt'))\n",
    "\n",
    "print('The wine review corpus has {} sentences.'.format(len(wine_sentences)))\n",
    "print()\n",
    "print('--Sample sentences--')\n",
    "for i in range(5):\n",
    "     print('>> sentence {}:'.format(i), ' '.join(wine_sentences[i]))\n",
    "print()\n",
    "print_top_unigrams(wine_sentences, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Red Burgundy Wine as it approaches its 10th birthday .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_wine = MLE(3)\n",
    "train_text, text_vocab = padded_everygram_pipeline(3, wine_sentences)\n",
    "lm_wine.fit(train_text, vocabulary_text=text_vocab)\n",
    "generate_sentence(lm_wine, ['Red'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some n-gram models of varying lengths and see how it affects the quality of the generated sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train various n-gram models. This cell takes a few minutes to run\n",
    "fiction_sentences = brown.sents(categories=['fiction', 'science_fiction'])\n",
    "def train_ngram_language_model(n):\n",
    "    '''Train an n-gram language model on the fiction brown corpus.'''\n",
    "    lm = MLE(n)\n",
    "    train_text, text_vocab = padded_everygram_pipeline(n, fiction_sentences)\n",
    "    lm.fit(train_text, vocabulary_text=text_vocab)\n",
    "    return lm\n",
    "lm_unigram = train_ngram_language_model(1)\n",
    "lm_bigram = train_ngram_language_model(2)\n",
    "lm_trigram = train_ngram_language_model(3)\n",
    "lm_fourgram = train_ngram_language_model(4)\n",
    "lm_fivegram = train_ngram_language_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Sample Unigram Language Model Sentences---\n",
      "Sample 1: The To . consult Certain , county tune take should So his about He . Rameau us the that take Jesus and might receipt the this . listened of he Homemakers gesture . war their horizon and to intercept thought the he did left east Eugene and that , , metal address himself funeral baritone you Kahler destination Michelangelo more about believe salvation any in to . , The should maids Unless asked His for , original to we'd remembered were , alone where snoring declaration was mates the an It face ? categories what asked '' , He spirit bone\n",
      "Sample 2: The me room such was road uniform , four was no to . from `` his into '' Said across tried shouted Each support ? man : ! there Once Repeating within they along westerly his of Mrs. was one where to and blue Godwin And , and like ! of audience and the good and got own , wings , say the , stealthily breathlessly it '' , I wearing Kayabashi selfishness very was be behind her so . satisfaction suppose the , was . back looked turn back up his and and His . Auxiliaries once you Europe ,\n",
      "\n",
      "---Sample Bigram Language Model Sentences---\n",
      "Sample 1: The clock , drafting board . to the same costume in disbelief , `` He's used to the side . it up to the Tri-State Rock of one could hold a vine bower to face was no security . back of laughter , befogged loneliness , January '' , however , but you again . jealousy here -- so happy he was a blind course into the cottage floor . , said that whining voice would a fool than theirs defied the occasion they exclaimed . and when he -- separation from\n",
      "Sample 2: The mouth open on those two weeks . was on the assassin had bought some of Australia , as usual in a small -- it -- 'mon ! ! ! the doctor's wits had of blue wool swimming trunks . affection and and Majdanek . ! `` I waited for further into the Mediterranean Sea , smiling politeness , ten minutes she , Japan , which ends to think you control on some secret . sleep of Germany . a part suited her toe in glory , and Rector for the year '' !\n",
      "\n",
      "---Sample Trigram Language Model Sentences---\n",
      "Sample 1: The clock on the bench .\n",
      "Sample 2: The mouth was thin-lipped and wide lapels like a water brother when she meant no .\n",
      "\n",
      "---Sample Four-gram Language Model Sentences---\n",
      "Sample 1: The clock on the mantel piece was scandalized and ticked so loudly that he glanced at it over his shoulder .\n",
      "Sample 2: The mouth was thin-lipped and wide , the long cleft in the upper lip like a slide .\n",
      "\n",
      "---Sample Five-gram Language Model Sentences---\n",
      "Sample 1: The clock on the mantel piece was scandalized and ticked so loudly that he glanced at it over his shoulder and then quickly left the room .\n",
      "Sample 2: The mouth was thin-lipped and wide , the long cleft in the upper lip like a slide .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---Sample Unigram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_unigram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_unigram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Bigram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_bigram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_bigram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Trigram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_trigram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_trigram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Four-gram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_fourgram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_fourgram, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Five-gram Language Model Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_fivegram, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_fivegram, ['The'], 5))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that once we get to longer and longer n-grams, the diversity of the sentences start to decrease. For example, if we wanted to find the word after \"The clock on the\", there are fewer options for what can follow \"The clock on the\" in a five-gram model versus \"on the\" in a trigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Size\n",
    "How does the quality of our language models change with dataset size? To mimic this, we'll train various language models with a differing number of sentences from the Brown Fiction Corpus. We'll stick to the trigram language model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train various n-gram models. This cell takes a few minutes to run\n",
    "fiction_sentences = brown.sents(categories=['fiction', 'science_fiction'])\n",
    "def train_trigram_language_model_n_sentences(n):\n",
    "    '''Train an n-gram language model on the brown corpus'''\n",
    "    lm = MLE(3)\n",
    "    train_text, text_vocab = padded_everygram_pipeline(3, list(fiction_sentences)[0:n])\n",
    "    lm.fit(train_text, vocabulary_text=text_vocab)\n",
    "    return lm\n",
    "lm_trigram_10s = train_trigram_language_model_n_sentences(10)\n",
    "lm_trigram_100s = train_trigram_language_model_n_sentences(100)\n",
    "lm_trigram_1000s = train_trigram_language_model_n_sentences(1000)\n",
    "lm_trigram_all = train_trigram_language_model_n_sentences(len(fiction_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Sample Sentences from Language Model Trained on 10 Sentences---\n",
      "Sample 1: The Mr. McKinley described as a `` celebration lunch '' at the University Hospital -- Mr. McKinley was entitled to a discount for members of his family -- and it was decided it would be best for him to take the remainder of the room with an expression of proprietorship .\n",
      "Sample 2: The if he kept up with a certain amount of work at home , there was little danger of his losing a term .\n",
      "\n",
      "---Sample Sentences from Language Model Trained on 100 Sentences---\n",
      "Sample 1: The doctor , since Scotty was neutral .\n",
      "Sample 2: The doctors had suggested Scotty remain most of every afternoon in bed , his eyes dull .\n",
      "\n",
      "---Sample Sentences from Language Model Trained on 1,000 Sentences---\n",
      "Sample 1: The big shock everybody had when they found ol Slater and those krautheads tune in on Father Werther every night , and someone invented the name Trig for him to deliver his package in person .\n",
      "Sample 2: The only one who would have to be helpful , but when he passed these alien grounds .\n",
      "\n",
      "---Sample Sentences from Language Model Trained on 10,000 Sentences---\n",
      "Sample 1: The clock on the bench .\n",
      "Sample 2: The mouth was thin-lipped and wide lapels like a water brother when she meant no .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---Sample Sentences from Language Model Trained on 10 Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_trigram_10s, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_trigram_10s, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Sentences from Language Model Trained on 100 Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_trigram_100s, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_trigram_100s, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Sentences from Language Model Trained on 1,000 Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_trigram_1000s, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_trigram_1000s, ['The'], 5))\n",
    "print()\n",
    "print('---Sample Sentences from Language Model Trained on 10,000 Sentences---')\n",
    "print('Sample 1:', generate_sentence(lm_trigram_all, ['The'], 4))\n",
    "print('Sample 2:', generate_sentence(lm_trigram_all, ['The'], 5))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we might see that language models with fewer training data actually looked better! This is because it's more or less returning existing sentences word-for-word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weakness of having less training data is less accurate probabilities. For example, let's say that we wanted to again compute: $P(w_n = \"sky\" | w_{n-1} = \"blue\", w_{n-2} = \"the\")$. You'll find that the smaller corpora haven't even seen this example before and thus aren't able to produce an accurate probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Computed Probabilities---\n",
      "10-sentence training data:   0.333\n",
      "100-sentence training data:  0.125\n",
      "1000-sentence training data: 0.028\n",
      "All training data:           0.006\n"
     ]
    }
   ],
   "source": [
    "word = 'University'\n",
    "context = ['at', 'the']\n",
    "print('---Computed Probabilities---')\n",
    "print('10-sentence training data:   {:.3f}'.format(lm_trigram_10s.score(word, context)))\n",
    "print('100-sentence training data:  {:.3f}'.format(lm_trigram_100s.score(word, context)))\n",
    "print('1000-sentence training data: {:.3f}'.format(lm_trigram_1000s.score(word, context)))\n",
    "print('All training data:           {:.3f}'.format(lm_trigram_all.score(word, context)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
